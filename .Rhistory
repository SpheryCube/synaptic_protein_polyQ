# Downloads complete
##########################
#############
# Preliminary Diagnostics
proteins <- read.csv(paste0(output_base_dir, "fly/fly_prots.csv"), stringsAsFactors = FALSE)
protein_lengths <- unlist(lapply(proteins$peptide_seq, function(x){length(unlist(strsplit(x, "")))}))
# protein_lengths <- proteins$peptide_length
# ggplot() + aes(protein_lengths)+ geom_histogram(binwidth=1, colour="black", fill="white")
# Length of universe proteins
p <- ggplot() +
aes(protein_lengths)+
geom_histogram(show.legend = FALSE, aes(fill=..count..), binwidth = 50) +
xlim(c(0, 7500)) +
ylim(c(0, 2100)) +
xlab("# of Amino Acids") +
ylab("# of Proteins") +
ggtitle(paste0("Fly Protein Length Histogram (All Proteins)")) +
theme_light()
print(p)
# Length of synapse proteins
synapse_term1 <- "GO:0045202"
synapse_cats <- get(synapse_term1, GOCCOFFSPRING)
synapse_cats <- c(synapse_cats, synapse_term1)
#synapse_only <- proteins %>% filter()
proteins_synapse_only <- proteins[unlist(
lapply(
lapply(proteins$go_ids_CC, function(x){unlist(strsplit(x, "; "))}),
function(x){any(x %in% synapse_cats)}
)
)
,]
nrow(proteins); nrow(proteins_synapse_only)
synapse_protein_lengths <- unlist(lapply(proteins_synapse_only$peptide_seq, function(x){length(unlist(strsplit(x, "")))}))
p <- ggplot() +
aes(synapse_protein_lengths)+
geom_histogram(show.legend = FALSE, aes(fill=..count..), binwidth = 50) +
xlim(c(0, 7500)) +
ylim(c(0, 2100)) +
xlab("# of Amino Acids") +
ylab("# of Proteins") +
ggtitle(paste0("Fly Protein Length Histogram (Synaptic Proteins)")) +
theme_light()
print(p)
# There are some outliers....
summary(synapse_protein_lengths)
summary(protein_lengths)
t_test_res <- t.test(synapse_protein_lengths, protein_lengths)
t_test_res$p.value
# Try capping to deal with outliers...
# http://r-statistics.co/Outlier-Treatment-With-R.html
cap <- function(vec) {
x <- vec
qnt <- quantile(x, probs=c(.25, .75), na.rm = T)
caps <- quantile(x, probs=c(.05, .95), na.rm = T)
H <- 1.5 * IQR(x, na.rm = T)
x[x < (qnt[1] - H)] <- caps[1]
x[x > (qnt[2] + H)] <- caps[2]
return(x)
}
synapse_protein_lengths_capped <- cap(synapse_protein_lengths)
protein_lengths_capped <- cap(protein_lengths)
summary(synapse_protein_lengths_capped)
summary(protein_lengths_capped)
t_test_res <- t.test(synapse_protein_lengths_capped, protein_lengths_capped)
t_test_res$p.value
#################################################################################################
training_id_dict <- list("mouse_Q"=c("FBpp0289769","FBpp0307700", "FBpp0086727", "FBpp0111724", "FBpp0070830", "FBpp0309352", "FBpp0402897", "FBpp0110299","FBpp0305807"),
"mouse_M" = c("NA", "NA"),
"worm_Q" = c("Something", "Something"))
# Now do the analyses...
for (species in species_vec) {
# debugging; species = species_vec[1]
output_species_dir <- paste0(output_base_dir, species, "/")
dir.create(output_species_dir, recursive = TRUE)
protein_df_w_seqs <- read.csv(paste0(output_species_dir, species, "_prots_filt.csv"), stringsAsFactors = FALSE)
for (candidate_AA in candidate_AA_vec) {
# debugging; candidate_AA = candidate_AA_vec[1]; candidate_AA
print(paste0("Species: ", species,"; Amino acid: ", candidate_AA))
output_AA_dir <- paste0(output_species_dir, candidate_AA, "/")
dir.create(output_AA_dir, recursive = TRUE)
# Use either 1 or 2.
# 1.) Hard coded training
training_set_ids <- training_id_dict[["mouse_Q"]]
training_set <- read.csv("C:/UROPs/polyQ_neuronal_proteins/output/fly/fly_prots.csv", stringsAsFactors = FALSE)
training_set <- training_set %>% filter(ensembl_peptide_id %in% training_set_ids)
# 2.) Soft coded training
# training_set_ids <- test_id_dict[[paste0(species, "_", candidate_AA)]]
# training_set <- protein_df_w_seqs %>% filter(ensembl_peptide_id %in% training_set_ids)
# Remove duplicates
vec <- duplicated(training_set[,c("ensembl_peptide_id")])
training_set <- training_set[!vec,]  # Remove duplicated rows.
# Train model on training set
print("Generating the model...")
trained_model <- train_HMM(training_set, candidate_AA)
print("Finished making the model!")
# Use trained HMM model on testSet (proteinSet).
proteinSet <- protein_df_w_seqs
protein_df_w_hmm <- test_HMM(proteinSet, trained_model, candidate_AA)
# Order so most relevant proteins are at the top.
protein_df_w_hmm <- protein_df_w_hmm %>% arrange(desc(HMMhasPolyAA), desc(MaxLengthsPolyAA), desc(AvgPolyAARegionAAFractions))
# Save HMM annotation results.
write.csv(protein_df_w_hmm, file = paste0(output_AA_dir, species, "_", nrow(protein_df_w_hmm), "prots_w_HMM_", candidate_AA, ".csv"), row.names = FALSE)
# Find genes where alternative splicing results in some isoforms having polyQ and others not having polyQs.
protein_df_w_hmm_alt_spliced <- protein_df_w_hmm %>%
group_by(ensembl_gene_id) %>%
filter(sum(HMMhasPolyAA) < n(),  1 < sum(HMMhasPolyAA))
protein_df_w_hmm_alt_spliced <- protein_df_w_hmm_alt_spliced %>%
arrange(ensembl_gene_id,
desc(HMMhasPolyAA),
desc(MaxLengthsPolyAA),
desc(AvgPolyAARegionAAFractions))
write.csv(protein_df_w_hmm_alt_spliced, file = paste0(output_AA_dir, species, "_", nrow(protein_df_w_hmm_alt_spliced), "prots_w_HMM_", candidate_AA, "_alt_spliced.csv"), row.names = FALSE)
#########################################################
# ClusterProfiler
# Use clusterProfiler to compare proteins with polyAA to all proteins
#########################################################
# Load in protein set data from local storage if you didn't download the sets from above
proteins <- read.csv( paste0(output_AA_dir, species, "_", nrow(protein_df_w_hmm), "prots_w_HMM_", candidate_AA, ".csv"))
polyAA_proteins = proteins %>% filter(proteins$HMMhasPolyAA == TRUE)
if (species == "fly") {
OrgDb = org.Dm.eg.db
fromType = "FLYBASEPROT"
} else if (species == "human") {
OrgDb = org.Hs.eg.db
fromType = "ENSEMBLPROT"
} else if (species == "mouse") {
OrgDb = org.Mm.eg.db
fromType = "ENSEMBLPROT"
} else if (species == "worm") {
OrgDb = org.Ce.eg.db
fromType = "ENSEMBLPROT"
}
# Filter out nuclear proteins here using CC category
# proteins <-
# Do enrichment for each subontology of GO
# ###########################################
# clusterProfiler Part 1 - GO
# ###########################################
for (go_ont in c("BP", "MF", "CC")) {
# go_ont <- "BP"
print(paste0("Doing enrichment analysis for ", go_ont, " ontology."))
# Only allow proteins that have annotations in current ontology to be in background universe.
proteins_has_ont_type <- proteins %>% filter(!is.na(eval(parse(text=paste0("go_ids_", go_ont)))))
nrow(proteins); nrow(proteins_has_ont_type)
proteins_vec <- unique(proteins_has_ont_type$ensembl_peptide_id)
# length(proteins_vec); length(proteins_has_ont_type$ensembl_peptide_id)
# Get only significant proteins that have annotation in ont.
polyAA_proteins <- proteins_has_ont_type %>% filter(HMMhasPolyAA == TRUE)
polyAA_proteins_vec <- unique(polyAA_proteins$ensembl_peptide_id)
length(polyAA_proteins_vec)
universe_df <- bitr(proteins_vec,
fromType = fromType,
toType = c("ENTREZID", "SYMBOL"),
OrgDb = OrgDb)
universe_genes <- unique(universe_df$ENTREZID)
# Get mapping from ensembl to entrez (entrez ids are needed for)
sig_df <- bitr(polyAA_proteins_vec,
fromType = fromType,
toType = c("ENTREZID", "SYMBOL"),
OrgDb = OrgDb)
# Create vector of  entrez ids for significant genes.
# Not there can be a 1 to many mapping from ensembl to entrez in the above step.
# thus we need to use 'unique'.
sig_genes <- unique(sig_df$ENTREZID)
# Create vector of entrez ids for a random set of genes that is the same size
# of the set of significant genes in order to control for sample size. (FDR adjustment should do this,
# but we are going to add this step just for kicks)
# Create vector of random control genes with same number as significant genes.
control_genes <- sample(universe_genes, length(sig_genes))
print(paste0("Length control genes: ", length(control_genes)))
# Test
go_enrich_output_test <- enrichGO(gene = sig_genes,
universe = universe_genes,
OrgDb = OrgDb,
ont = go_ont,
pAdjustMethod = "BH",
pvalueCutoff = 0.05,
qvalueCutoff = 0.05,
readable = TRUE)
# Control group
go_enrich_output_control <- enrichGO(gene = control_genes,
universe = universe_genes,
OrgDb = OrgDb,
ont = go_ont,
pAdjustMethod = "BH",
pvalueCutoff = 1,
qvalueCutoff = 1,
readable = TRUE)
# clusterProfiler Plots
# Make plots for the control group.
if (!is.null(go_enrich_output_control)) {
go_control_result <- go_enrich_output_control@result
write.csv(go_enrich_output_control, file = paste0(output_AA_dir,  species, "_", candidate_AA, "_Control_Enriched_GO_", go_ont, ".csv"), row.names = FALSE)
pdf(paste0(output_AA_dir,  species, "_", candidate_AA, "_Control_Enriched_GO_", go_ont, "_plots.pdf"), width = 8.5, height = 11)
par(mfrow = c(1, 1))
p1 <- barplot(go_enrich_output_control, showCategory=8)
p2 <- dotplot(go_enrich_output_control)
print(p1)
print(p2)
if (nrow(go_enrich_output_control) != 0) {
p3 <- emapplot(go_enrich_output_control)
# p4 <- cnetplot(go_enrich_output_control,
#                categorySize = "pvalue",
#                foldChange = control_df$ENTREZID,
#                node_label = FALSE,
#                colorEdge = TRUE)
print(p3)
# print(p4)
}
dev.off()
}
make_enrichment_plots_and_files <- function(go_enrich_output, type) {
if (!is.null(go_enrich_output)) {
go_result <- go_enrich_output@result
if (type == "control") {
write.csv(go_enrich_output_control, file = paste0(output_AA_dir,  species, "_", candidate_AA, "_Control_Enriched_GO_", go_ont, ".csv"), row.names = FALSE)
pdf(paste0(output_AA_dir,  species, "_", candidate_AA, "_Control_Enriched_GO_", go_ont, "_plots.pdf"), width = 8.5, height = 11)
} else {
write.csv(go_enrich_output, file = paste0(output_AA_dir, species, "_", candidate_AA, "_Enriched_GO_", go_ont, ".csv"), row.names = FALSE)
pdf(paste0(output_AA_dir, species, "_", candidate_AA, "_Enriched_GO_", go_ont, "_plots.pdf"), width = 8.5, height = 11)
}
par(mfrow = c(1, 1))
p1 <- barplot(go_enrich_output, showCategory=8)
p2 <- dotplot(go_enrich_output)
print(p1)
print(p2)
if (nrow(go_enrich_output) != 0) {
p3 <- emapplot(go_enrich_output)
# p4 <- cnetplot(go_enrich_output,
#                categorySize="pvalue",
#                foldChange=sig_df$ENTREZID,
#                node_label = FALSE,
#                colorEdge = TRUE)
print(p3)
# print(p4)
}
category_to_proteins = read.csv(text="GO_id,GO_desc,p.adjust,avg_peptide_length")
# Iterate over each enriched category, seeing if the length of the proteins in that category are correlated
# with the p-value of that category
enrich_results <- go_enrich_output@result %>% filter(p.adjust < 0.05)
if (nrow(enrich_results) > 0) { # Make sure there is actually stuff to iterate over.
for (i in 1:nrow(enrich_results)) {
row <- enrich_results[i,]
cat <- row$ID  # Enriched category
cat_gene_syms <- strsplit(row$geneID, split = '/' ) # Gene symbols of genes in category.
# Get the peptide ids of all the genes that were in this enriched category.
peptide_ids <- with(universe_df[universe_df$SYMBOL %in% cat_gene_syms[[1]],], get(fromType))
# Now get their lengths
df <- proteins[proteins$ensembl_peptide_id %in% peptide_ids,]
# mean(df$peptide_length())
mean <- mean(unlist(lapply(as.character(df$peptide_seq), function(x){length(unlist(strsplit(x, "")))})))
category_to_proteins[i,] <- list(row$ID, row$Description, row$p.adjust, mean)
}
# Make p-value vs
x = category_to_proteins$avg_peptide_length
y = category_to_proteins$p.adjust
fit <- lm(y ~ x)
p <- ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point(shape = 1) +
stat_smooth(method = "lm", col = "red") +
labs(title = paste("Avg Length of Peptides in Enriched Category VS p-value of Enriched Category \n",
"Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" P =",signif(summary(fit)$coef[2,4], 5))) +
xlab("Average Peptide Length of Category") +
ylab("Adjusted p-value of Category") +
theme_light() +
theme(plot.title = element_text(hjust = 0.5))
print(p)
} # for (i in 1:nrow(enrich_results)) {
dev.off()
} # if (!is.null(go_enrich_output)) {
} # make_enrichment_plots_and_files
make_enrichment_plots_and_files(go_enrich_output_control, type = "control")
make_enrichment_plots_and_files(go_enrich_output_test, type = "test")
} # for (go_ont in c("BP", "MF", "CC")) {
# ###########################################
# clusterProfiler Part 2 - KEGG
# kegg_enrich_output <- enrichKEGG(gene = sig_df$ENTREZID,
#                                  organism = "dme",
#                                  keyType = "ncbi-proteinid",
#                                  pvalueCutoff = 0.05)
#
# kegg_result <- kegg_enrich_output@result
# if (nrow(go_enrich_output) != 0)
# {
#   write.csv(go_enrich_output, file = paste0(output_dir, group_name, "Enriched_KEGG.csv"), row.names = FALSE)
# }
############################################################################3
################################## Plotting ##################################
############################################################################
# Number of randomly chosen 50 amino acid peptide chunks [WORKS]
# Plotting helper function
rnd_substr <- function(x, length) {
if (nchar(x) < length) {return(x)}
else {
start = sample(1:(nchar(x)-length), 1, replace=T)
end = start + (length-1)
random_substring = substr(x, start, end)
return(random_substring)
}
}
###########################################
pdf(paste0(output_AA_dir, species, "_", candidate_AA, "_", nrow(proteins), "prots_result_plots.pdf"))
########################################################
#######################
# Plot type: Whole Protein Qfraction Histogram for all proteins
p <- ggplot(data = proteins, aes(x = proteins$AAfraction)) +
geom_histogram(show.legend = FALSE, aes(fill=..count..)) +
xlab(paste0("Whole Protein %", candidate_AA)) +
ylab("# Proteins") +
ggtitle(paste0("%", candidate_AA, " Whole Protein")) +
theme_light()
print(p)
filtered_df <- proteins %>% filter(proteins$AAfraction > quantile(proteins$AAfraction, 0.95))
filtered_df <- filtered_df %>% arrange(desc(filtered_df$AAfraction))
write.csv(filtered_df, file = paste0(output_AA_dir, candidate_AA, "fraction_all_wholeProts_95sig.csv"))
# Plot type: Whole Protein AAfraction Histogram split by HMMhasPolyAA
p <- ggplot(data = proteins, aes(x = AAfraction, fill = HMMhasPolyAA)) +
geom_histogram(alpha=0.5, position="identity") +
xlab(paste0("%", candidate_AA, " (Whole Protein Seqs)")) +
ylab("# Proteins") +
labs(fill = paste0("Contains \n poly", candidate_AA)) +
ggtitle(paste0("%", candidate_AA," Whole Proteins Histogram")) +
theme_light()
print(p)
p <- ggplot(data = proteins, aes(x = AAfraction, fill = HMMhasPolyAA)) +
geom_density(alpha = 0.5) +
xlab(paste0("%", candidate_AA, " (Whole Protein Seqs)")) +
ylab("Density") +
labs(fill = paste0("Contains \n poly", candidate_AA)) +
ggtitle(paste0("%", candidate_AA, " Whole Proteins Density Plot")) +
theme_light()
print(p)
########################################################
# Plot type: 100000 50AA chunks, each randomly chosen from randomly chosen Protein seqs
df <- sample_n(proteins, 100000, replace = TRUE)
df$RandomSeqs <-unlist(lapply(as.character(df$peptide_seq), rnd_substr, 50))
nAAs = str_count(df$RandomSeqs, candidate_AA)
df$AAfractionRandomSeq <- nAAs/nchar(df$RandomSeqs)
p <- ggplot(data = df, aes(x = df$AAfractionRandomSeq)) +
geom_histogram(show.legend = FALSE, aes(fill=..count..)) +
xlab(paste0("%", candidate_AA, " (Random 50AA Seqs)")) +
ylab("# of Randomly Choosen Pepitides") +
ggtitle(paste0("%", candidate_AA, " for 100000 50AA Random Seqs Histogram")) +
theme_light()
print(p)
filtered_df <- df %>% filter(df$AAfractionRandomSeq > quantile(df$AAfractionRandomSeq, 0.95))
filtered_df <- filtered_df %>% arrange(desc(filtered_df$AAfractionRandomSeq))
write.csv(filtered_df, file = paste0(output_AA_dir, "AAfraction_randomAAs_95sig.csv"))
########################################################
# Plot type: Number of Proteins annotated by HMM to be "Poly AA" vs %AA
p <- ggplot(data = df, aes(x = as.numeric(df$AvgPolyAARegionAAFractions))) +
geom_histogram(show.legend = FALSE, aes(fill=..count..)) +
xlab(paste0("Avg %", candidate_AA, " of poly", candidate_AA, " Regions")) +
ggtitle(paste0("Avg %", candidate_AA, " of poly", candidate_AA," Regions for poly", candidate_AA, " Containing Proteins")) +
ylab(paste0("# Proteins Containing poly", candidate_AA)) +
theme_light()
print(p)
df <- proteins %>% filter(HMMhasPolyAA == TRUE)
p <- ggplot(data = df, aes(x = df$MaxPolyAARegionAAFractions)) +
geom_histogram(show.legend = FALSE, aes(fill=..count..)) +
xlab(paste0("Max %", candidate_AA, " of poly", candidate_AA, " Regions")) +
ggtitle(paste0("Max %", candidate_AA, " of Poly", candidate_AA, " Regions for poly", candidate_AA, " Containing Proteins")) +
ylab(paste0("# Proteins Containing poly", candidate_AA)) +
theme_light()
print(p)
##############
# Plot type 4: Number of Proteins annotated by HMM to be Poly Q vs Length of Region
p <- ggplot(data = df, aes(x = df$AvgLengthsPolyAA)) +
geom_histogram(show.legend = FALSE, aes(fill=..count..)) +
xlab(paste0("Average Poly", candidate_AA, " Length")) +
ylab(paste0("# Proteins Containing poly", candidate_AA, " (by HMM)")) +
ggtitle(paste0("Average Poly", candidate_AA, " Length in Poly", candidate_AA, " Containing Proteins")) +
theme_light()
print(p)
p <- ggplot(data = df, aes(x = df$MaxLengthsPolyAA)) +
geom_histogram(show.legend = FALSE, aes(fill=..count..)) +
xlab(paste0("Max poly", candidate_AA, " Length")) +
ylab(paste0("# Proteins Containing poly", candidate_AA, " (by HMM)")) +
ggtitle(paste0("Max poly", candidate_AA, " in poly", candidate_AA, " Containing Proteins")) +
theme_light()
print(p)
p <- ggplot(data = df, aes(x = df$NumberPolyAA)) +
geom_histogram(show.legend = FALSE, aes(fill=..count..)) +
xlab(paste0("Number of poly", candidate_AA, " Regions")) +
ylab(paste0("# of ", candidate_AA, " Proteins")) +
ggtitle(paste0("Number of poly", candidate_AA, " regions in poly", candidate_AA, " Containing Proteins")) +
theme_light()
print(p)
dev.off()
}
}
############ End Plotting ################
#################################################################
#################### Misc. Code #################################
# ggplot(data = proteins, aes(x = proteins$Qfraction, y = ..count../sum(..count..))) +
#   geom_density() +
#   xlab("Q-fraction (Whole Protein Seqs)") +
#   ylab("Percent") +
#   theme_light()
# clusterProfiler needs entrenz id
# Add go Annotations
# head(listFilters(ensembl),20) # Stuff we can filter by
# head(listAttributes(ensembl), 20)# stuff we can retrive
# columns(org.Dm.eg.db)
# select(org.Dm.eg.db,
#        keys=as.character(protein_set$AccessionNumber), keytype="ACCNUM",
#        columns = c("GO", "SYMBOL", "ALIAS", "GENENAME", "UNIGENE", "UNIPROT"))
# getCollection( db = "ensembl",
#                organism = "Drosophila melanogaster",
#                path = file.path("_ncbi_downloads","collection"))
#
# getCollection( db = "refseq",
#                organism = "Drosophila melanogaster",
#                path = file.path("refseq","collection"))
# Read the protein sequence file, looks like:
# $A06852
# [1] "M" "P" "R" "L" "F" "S" "Y" "L" "L" "G" "V" "W" "L" "L" "L" "S" "Q" "L"
# ...
rm(list=ls()) #clear all memory
library(GEOquery)
library(Biobase)
library(GEOquery)
library(limma)
library(affy)
library(ggplot2)
install.packages(ggplot2)
install.packages("ggplot2")
library(ggplot2)
install.packages(colorspace)
install.packages("colorspace")
library(ggplot2)
library(gplots)
library(RColorBrewer)
library(Biobase)
library(GEOquery)
library(limma)
library(affy)
library(ggplot2)
library(devtools)
library(ggbiplot)
install.packages('backports')
library(devtools)
library(factoextra)
install.packages(factoextra)
library(factoextra)
install.packages("factoextra")
library(factoextra)
# Analysis Parameters
numGenes = 500                        # number of genes for top candidate DEGs table
fileOut <- 'topCandidateDEGs.txt'     # top candidate genes output name
pThresh = 0.05                        # p-value threshold for differential expression
getwd()
setwd(C:\IAP 2019\20-260\1-17-19\appliedOmicsAnalysis\output)
data <- read.csv("C:/UROPs/polyQ_neuronal_proteins/output/fly/Q/fly_22905prots_w_HMM_Q.csv")
#########################################
# Preliminary Diagnostics
#########################################
proteins <- read.csv(paste0(output_base_dir, "fly/fly_prots.csv"), stringsAsFactors = FALSE)
library(doParallel)
# HMM tools
library(HiddenMarkov)
library(seqHMM)
# Data manipulation tools
library(TraMineR)
library(stringr)
library(grid)
library(doParallel)
# HMM tools
library(HiddenMarkov)
library(seqHMM)
# Data manipulation tools
library(TraMineR)
install.packages(seqHMM)
install.packages("seqHMM")
library(seqHMM)
install.packages('checkmate')
library(seqHMM)
# Data manipulation tools
library(TraMineR)
library(stringr)
library(grid)
library(dplyr)
library(ggplot2)
library(ggrepel)
library(data.table)
# Biological databases and their tools
library(biomaRt)
install.packages(biomaRt)
install.packages("biomartr")
library(biomartr)
install.packages(S4Vectors)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("biomaRt", version = "3.8")
# Biological databases and their tools
library(biomaRt)
library(biomartr)
library(STRINGdb)
library(org.Dm.eg.db)
library(org.Hs.eg.db)
library(org.Mm.eg.db)
library(org.Ce.eg.db)
library(GO.db)
# Enrichment analysis tools
library(clusterProfiler)
install.packages("IRanges")
version
install.packages("IRanges")
library(org.Dm.eg.db)
install.packages("IRanges")
